This is fully overloaded.
Okay.
You that is.
So let me welcome you.
And the first session of the spring turned off seven, not a one to seven.
And it is my pleasure to come here, one off of a car weeks.
It will fall.
And I 'm really eager to know what well what everything can go wrong in life speech, sounds station.
So the floor.
The Ceo 's.
Thank you for the interaction.
Well, I 'm afraid that he will indeed see it life.
So so now this is a summary of the current status of the elite, the project where we are trying to do life supplied link into many target languages, and I will briefly describe how that works.
Well, give it one more trying.
If there is anything appearing, no does not seem.
So, Oh, yes, there is something is happening.
So it is maybe maybe at the bottom of the screen.
There will be the only subtitles of what I 'm saying," it is totally not certain that it can be many flaws in those in those do not scripts and deliberately were not showing that translation, because the translation has hard time in feeding into these two lines.
But if you have a, but if you have to you your machines ear, no books, or or maybe even cell phones with you.
There is a shared Google look human, which you probably know from previous Monday Seminars, and there is two links where you can see also the translations, not only in the transcripts, and you can choose the target languages.
I believe Hindi, is also among also among the target languages.
So there will be use some intention jokes during the presentation, and there will be many unintentional ones in the subtitles.
Please do not laugh too loud.
We we know what is a peer Inc, there.
But that is that is life that is work in progress.
So today.
I would like to briefly discuss the differences between mission physicians poker in which translation.
And then our summarize the ambition that our project has ah, a inch, because the ambition is is high.
We know it.
We are on a number of tests sessions.
And this is actually one of the test sessions as well.
So after the summary of the test sessions that that we are taking part in.
I will briefly summarize the old architecture.
And then I will go along all the possible issues of all the everything that can go wrong.
And that is why there is a long long list of things that that can go wrong.
And luckily, things to the number of inversions that we are trying this list of errors.
It is is so low on the errors that respond on.
Every new similar instance, is is not growing much.
So we still have the errors.
But luckily, we are close to seeing the known errors, which we have some ways, at least, in some cases, we which we have some ways to fix okay, and then will summarize and local direction this.
So again, down your.
So it would come early demanded tests.
That is where you can see the subtitles.
Okay, ah, we have been working.
We as the Department have been working on machine translation, for many years, or decays actually, ain 't it.
When you say machine translation.
We might mean text translation.
And there the import are sentences, which are, which are almost always grammatically," correct, and they may come in documents.
So you may have some content, some context surrounding the sentences, or you might also sometimes by sentence.
But it is definitely like sometimes based in spoken English translation.
The input is sound.
And the output is text.
We will get to some more details about.
What does this text, but sentences, some may or may not be produce, then actually them sometimes should not be assumed at all.
So maybe what we all know that we do not speak in sentences and figuring out where the sentence.
And this is a difficult part.
So that is there.
There will be some pension.
When when my putting these two components together, the speech recognition and the machine translation.
And there is one more area that I would like to just mention is called" incremental machine translation.
And there, this is machine translation, the researchers doing that.
So they start with the words words that come in sentences, and they just feed the system with the words, but one at time.
So the incremental missions.
Opposition is still to at least to my knowledge to my understanding is still takes the base translation.
It just comes award at time.
And there is different from the speech, which comes a second a dime, like a a bit of sound at a time, so that the time is different.
Even if we even if we go for some incremental doing.
Okay?
So this is in pictures, the ambition, or the the summary of the two technologies that are examined bar by our project.
We are trying to put to put together speech recognition and machine translation into spoken language translation.
Here, some history of ah, the speech recognition, but we have not really as department.
We have not really work on speech recognition.
So will I just copy this from from somewhere.
And it seems that the only from the eighties people run many share tasks and improve the the performance of of the recognition.
And here around two to four percent off word error rate.
That is where humans are not with the precision and on the E.
In early days.
In 1990, something some systems got to the human performance, and then on conversational speech, which is like unlimited is unlimited speech or meetings people.
The systems are far from this from this benchmark, but then has been changing, or the last two years thanks to the neural networks.
So this image more conversational speech, the benchmark that is 40 for the calls between two random English speakers there.
The human level of six percent has been kind of reaching two dozen 17.
So that seems like that speech recognition.
If it is the right thing.
It can work equally us equally well us as humans do.
Then this is the the the history of machine translation into check that you know, from previous presentations off from Martin Pope, well, and also then from me.
This is our systems.
And the last one is the Super Human machine translation system from English into check into does not 18.
Martin spa pearls set up was able to, you know, to outperform human translators like professional translators belittles Balk translation.
It was they.
They did not pay more attention to that, then the then look to their normal job.
So that was like the the average professional translation quality inch ever looted sentence by sentence.
Uh, the set up by Martin Papa was was significantly better than that.
Obviously, there is many caveats to uh, to uh, take into account.
But that is the that is the setting.
You have two technologies.
You have spoken English translation, which could be on par with humans, and you have machine translation.
Uh.
So, so we have the the speech recognition, which could be on par with the humans and machine translation, which could be on par with humans.
So that is where we said," let us join them.
Let us.
Let us get this.
Let us make use of this of these great to achievements.
Let us put them together.
So in our project to the L E.
The project.
We are trying to.
This will be badly miss recognize the because it does not recognize and the and the names of will sell in in the uh, the the project that we are putting together speech recognition and machine translation in highly multilingual setting I will mention that later on.
Well, we are Cordelia Project, the University of, but Edinburgh, including us, are experts in machine translation.
So to say called through his expert in inch speech recognition.
We have the top performing systems.
If we put them together.
I 'm sure it will work.
Great and pairwise is an Italian company.
They have also been involved in number of European projects before, and they were always in the role of the integrator.
So they know how to put things together, and they have some baseline systems that we can build up on.
And then we have a user partner all for you, which is remote conferencing system where we would like to translate what people do what people say in the in in the remote calls and Hiv and other user partner.
And there is the supream audit office of the Czech Republic.
And.
The Supreme Audit Office.
They are too afraid of of doing anything bad with with financing.
So did they did not want to get single Euro.
So they are not part of the project, but they are just then a few lady, you the partner.
So they are not supported by the European commission.
Uh, okay.
So the ambition.
The ambition is is very big.
We want to support a Congress that the Supreme audit office.
Runs this year.
In the end of may or early June, and the participants of that Congress come from many countries, and in some, they speak 43 languages.
So this is well beyond the capacity of a us off simultaneous interpreting by humans, and we want to provide the missing languages.
So to say, so, there will be six languages spoken at that.
Congress.
So English and French and Spanish German, Russian and check.
These are the official languages of the Congress.
This will be manually interpreted across so that all the six are provided, and we are to provide the remaining 43 other.
The the remaining that the rest of the 43 languages.
So this set off, you are selling, which is larger than this, artificially you languages.
And that is also an important remark, because many of these languages are much world as much shorter off of data.
So the European commission.
So the European Union has already put a considerable force into a date.
Our source is the for some years.
Everything from the European Parliament was translated into all the languages.
All the documents of the European Union are available in all the languages.
So we have something to train on before the stand for languages, but less soul for this 19 Edison languages.
And some of these languages have even so a brand new or unclear stayed, as they had no grammar.
Books were written for them yet.
So that is that is a challenge on its own.
Okay.
Yeah, so the events.
We know that this all should run.
So we have already started.
The project started last year in January, and in March.
We have added one extra dry run.
So in our project plan we have.
We had like two dry run sessions.
And then the Congress.
And we said," well, on the third attempt to do everything.
Well, so that as the 200 Delegates, or 400.
If you come the delegate and their and their fellow that the 400 people will see what what we have tested just two eyes beforehand.
That is impossible.
So we have added number of a number of other events.
The first one.
What happened in March.
Last year.
It was the student fare of fake, thermos-like mock mock business companies.
And there we were testing the altar and Pre existing technology would cause to ahead.
And what per was heard, and we just did our machine translation system from English interject then that we also got in touch with the as I do not know the good, the correct English name of the department, but the Department for interpreting in translation and the faculty of arts of our university.
And thanks to their support.
We are able to at the end.
There.
More conferences were the interpreters are getting train.
And we are recording the small people interpreters, and as the likes of seeing what our systems can do with that multiple inputs.
So this is this is like similar setting where there is in their brothers in the wars, and we are trying to follow what they are saying and complimented with the with the other languages.
And then we had the two official events that are planned for our uh, for project, that one was a working group on value, added tax, which happened in June, and then right after the summer in October.
There was another meeting.
So these two events were like quite close to each other, not so not much.
The development was possible between these two events.
And then in November, we also added one more was showing this technology in a little demo on the month is open doors.
They.
And I was also trying to present it at best of proxy AI event and.
Then in February, so, very simply it.
We.
Had workshop, a dry run of workshop, which will also go run at the Congress.
And there the purpose of the workshop is to demonstrate not only machine translation, but all other text processing or an opiate technologies to the audience to the lady users.
The Supreme orators.
It is is to illustrate how all the and Lp tools can help them in their business.
And we are going to run this workshop, obviously in English, and there will be the language barriers.
So the the orators would like to see some translations of of that.
So the successful a demo was only in November, this was the big failure, because they the wife.
I did not start.
Well, no mention that later on.
And then the the the long, close workshop.
Everything worked well, but it was actually still pretty useless for the users.
And and hopefully you will see in the following slides.
Why this is the case.
This is the upcoming events.
There is a game.
So the more conference is affected of ours will again for to see them.
There is another instance, of the student firms fair.
We are again, trying to uh, to get to that, because the size of the high school students have from across the Europe, provide beautifully non-native speech.
So they are very hard to uh, to understand for the ears are system.
So we.
We get the test sets there.
And Joe.
We are making it.
A shared are still to understand these high school students, then yes.
So uh, this is the this is the share task where we are trying to get also other Research Institute stood to the process that data that the high school students.
And then we will have a second run of all workshop.
Maybe we will add some other things.
And the main event is early June in here in Prague, and they are all them on this.
I mean, there is so again, and every Monday similar, you will have a chance to to see subtitles.
Ok.
So here is a very brief reported on last March event.
The student firms fair.
There was one speaker also with that we are.
We are like we.
We put the Mike to not only the students.
The much said," lodging the check Gm is economist.
And you see that it is the the the old system worked pretty well, including our check translations.
So he was speaking, and it was recognizing him.
It was recognizing sentences.
So for about minute, we have the perfect show.
And that was it from three days.
We had like one minute.
So what we started blogging.
And and we we block about all our successes.
The on our Web Page.
Blogging is fun, and so on so on.
So with blogging.
You immediately feel famous.
It does not really matter.
If any one follows you, just the fact that you posted somewhere that that makes you feel famous, and you can also sometimes improve the really to have it.
So the the uh, well, we do not do for a shopping of our.
Most of the only thing is what we do is we selected the bates.
The word" worked" so have from those today events.
It was one minute, and but we are going to bigger.
So so hopefully there will be almost almost 50 minutes of to day, which will be subtitled" Throughout the whole session.
So I said that the beginning as are an empty.
These are perfect technologies.
They work were.
Well, they are super human.
You just plug them together.
Well, it is not quite like that too.
You still need to acquire the sound to, you need to get the input, and you need to prison, the output.
And there is also the litter clash.
The speech took me to recognize his words, but we are ready to translate sentences.
So what you need to do is you need to segment.
That is three more for it is into sentences.
And then only then you can translate them so that actually that actually still requires you to to add one more components, some some segmenter segmentation worker, and you also need to ship all these bits of those three him to the various workers along the pipeline.
So the the two stem, just put the two steps together set up.
This is actually this this complicated.
So this is the or architecture.
It is builds upon something which her was developed in in the previous project.
It is called the paradise platform.
And to these components, all these components of speech recognition, and all all that connects to the central point call the mediator, and you have a client that climb comics to that mediator the muddy, their ships it.
So the ace are then to segment sentence, segmenter dental machine translation.
And then to presentation in the presentation delivers it to the vet and have we just receive like confirmation that this single word.
This second of sound was process the along the whole pipeline so this.
And this is the runs across the Europe.
So some of these components on here in this building.
Some of them run somewhere in the cloud of pairwise.
Some run in Edinburgh, some running cars through it.
So that is is is this through beauty to the connections are always open, and the reuse across the clients about it through a re uses one particle type of Internet communication that these Cp protocol.
And that requires that the network is is very broad in in the connection.
So that it.
It does not go collect any delay.
Any like this is the set up.
That also includes the wiring.
So you need to like calling the the machines that the microphones and and cunning, the prison, think system to the screen, and all that.
And this is the set of for the year cycle grows where there is six interpret this booth in all the Mary is on the many sick to all the six languages that though that humans interpret into.
And there we are collecting all those then and choosing which one of them to translate from and then translate to all the remaining 30, something languages.
So the set of this are complicated.
This is the workers connected to the media platform, and you see that some of them are busy and some of them are available.
So this, this is like a big infrastructure.
So let us start with some of the issues, obviously the network and slow things down.
So once we face is the fact that in Consul where there was some construction or whatever.
For some reason, the University had little slower Internet access, and that delayed all our processing.
So little immediately, we were not live.
But we were like second sword, dozens of second thoughts later than the signal.
So you you should be actually on stage or it very close to the venue.
If you want to deliver somewhat in the speech reliably for debts that this is not problem.
But if you wanted to do it life you you.
You should not rely on on the Internet.
And this was the problem.
And the best of Frock AI, is session where I have tested everything it.
Worked perfectly for the demo.
Uh, unfortunately, even like I have lost a month before hand.
And then for second time, I was not allowed to conduct my machine tool.
Wired connection.
I had to rely on why fight.
And everything worked twice when was at the venue at this that it.
Then the audience came and the audience broad their cell phones.
Nobody actually use the Internet.
The the cell phones were just trying to like look around is there any internal available, and they tried to connect.
And and maybe just these tests simply kill the wife.
Why?
And it did not work for me, and also on nothing was ever recognized that even for me.
So.
So we must not rely on wire wireless connection.
Then we also had issues where everything went well, except the the the the final presentation was like of filling buffers off web-browsers.
So.
It was not showing properly on the end user device.
It is everything was OK until the final presentation point.
And.
This is another.
This is like miss configuration ever like if your juggling with with the set up.
So it is easy to make mistake.
So in one of the sessions.
We were observing some horrible.
The lady gaining are growing.
And the reason was that we are in our own solar system, because we are also experimenting with that.
And we rented locally about accidentally.
We were first sending the sound or via fight to Italy, and then sending in the bank to our place to recognize it.
And only then we we are.
We are recognizing it.
So this double double network low to has killed that has caused the delay next time we.
We would like to recognize it on the spot.
And and the the problem was gone again.
Now, sound acquisition.
You may recognize some of uh, one of our colleagues here.
And the problem is if if you have this microphone that just microphone, and you put it here.
And then you talk to the slice like that.
The microphone does not really get your ways.
So that is that is one problem.
This is another thing right now.
I would untrue to unfortunate.
We had to switch off this just Mike number lying on this mouth.
Mike, we wanted to extend this test.
So based on a three minutes of thus testing the error in recognizing English, and check is of use several points, the lower.
If you use the mouth microphone compared to the chest microphone.
So they are just distance from the mouth and the movement of the head that makes the measurable measurable difference.
So we are relying on the on the better on the head microphone in this paper for singers.
So for vocalists.
The you have to hold the Mike properly.
You have you have not the view.
You must not put it in your mouth.
Almost, you must not put it too far away from your mouth.
And also, if you stand in front of the loudspeakers, the reverberations, will will totally kill the signal that you are receiving through my.
So this is what has happened to us during the uh, the student from first one, the students were were just roaming around, and they and the the area in front of the loudspeakers.
And suddenly there was no way to to recognize them OK and.
Then the various cables.
You, have to plug the cables properly.
And one of the settings in the of the conference in room for the interpreters.
We were able to get the signal.
Only when one of the connectors.
Here was not fully plugged in.
The reason is that we were like misusing, the the connections.
So.
Once once we brought a proper sound card.
It was able to recognise which, been of that the, conductor has want, but, with the proper, some colleges', the building some kind of standard notebook.
You have to like Miss align.
The the pince are all that connected to it to get the signal.
So so the there was an hour or two of debugging until we figure out how to connect the input.
So that is we are learning.
So then there is the volume setting along the along the pipeline.
So.
If you have a wireless microphone.
It has a receiver, and there is volume can throw the receiver, and then you have a sound card, and that also has some blue control.
And it also has some barton, like two buttons.
So line level, or make level that is one button and putting on or off.
So you have to that is like four options, at least just for the buttons, and then for the for the for the knobs, and you have to the said this.
So this properly.
Otherwise.
The sound can be the quiet, or the sound will be too too high.
If the the volume would be too high, and someone along the pipeline will clear bit.
And then you do not get the frequent frequencies, and the ears are what will not work.
So you need to carefully thread this signal step.
By step experience.
People know.
I remember the the good colleague from the paper was company who came for the student fares have for the first time.
And there we still were struggling with getting the signal, right?
And he like follow through on the Mike with the headphones always connected as phones.
And and that OK it.
Is good here.
Is good here, and.
And step by step.
He managed to deliver the the right volume to the machine.
So that is you have to do.
It is the price, and it can fail at any point.
Yep.
So then it is our quality.
So once you have delivered the possible the best possible signal.
What does the mission recognize from that.
So this is an example from the from the student, the high school students.
They have.
The speaker wanted to say something like you have a boat to, Oh, yes, we are situated in the harsh in the heart of just good.
Would you know it is.
But in the really did.
This is high school student.
So he said," you have a bottle.
Oh, yes, we are situated in heart of just get rid of it, so that there was serious miss pronunciation.
And there was also high level of background noise, because that is fair.
So there is the stands with music playing in.
We are just behind a little a little wall, a hoping to get.
Some some shows are from from all that nice.
So if you are an expert, if you are a person.
And you are in this here in this in this harsh conditions.
Then you are probably understand something like you have a bottle, because you are not expecting the the student to talk about a hold on the boat.
Oh, yes, we are situated in the heart of all.
And then he would recognize that some cities being mentioned.
But if he is from Spain, he would not know that just they would.
You know, is a is a is a check city.
This thundered a us our Lord deliver something like, Oh, yes, the the of the that is the the few words of his heart and sport in the in the noise signal is the a 's star is its noise resistant.
If it can somehow cancelled the noise.
Then it will do something you have somebody to Oh, yes, we are situated in hard, which is can we do, because it does not know the the name of that takes it in.
And if we have a future as our or a person in the in the middle actually, and then we would get the the proper recognition of the sentence.
So this is a.
This is all the problems that that we are facing when we are trying to transcribe and non-native speakers.
This is summary occurs the recordings that we may have made their.
So remember, the word" error" rate for humans is around six or four percent here, the Google system, Google, as our head error rate of of nine dish.
Edinburgh system also show and car also system was actually the best one around 40 still ten times worse than the was the humans do.
And this is this is on the recordings were all the systems have produced any output whatsoever.
If we apply if we if people have the same figures.
But we found a 100 percent of others as the the the score.
If no output is delivered them.
Google is so much worse than any imbera.
So I remember was was better.
It was not like giving up.
So frequently, Carlos was still still the best system, but still the the car through a system is ten times worse than the humans.
And that is then what is reported in the literature.
Obviously.
This is hard conditions.
So this is the ground, no is non-native speakers.
Well.
We are not yet quite profession in the recording.
So we just misaligned, the mikes, and people like those poked you too loud.
And we did not do.
That was the knobs of properly.
So it is it is very harsh conditions.
But this is the the the really do that that you can get.
So this is the best recording according to the as our quality, and there are things like, why do you wear those.
So high heels is that.
Why do you wear those high heat the high heels.
And she deals in there is no one really good star, instead of the store that deals with the sale of free down food, instead of free time, footwear, or something like that.
So it is it is the totally wrong.
Ok.
So what is our plan given this.
So we are definitely going to retrain our his arm orders, and I really would like to use non Native speech corpora, common voice by Mozilla is one of this is that that can help.
And we have another fall like uh, the thing to do.
We would like to follow interpreters instead of the floor, because each of the interpreter will sit in the booth with limited snow is from surroundings with better microphone.
So we have more control of the recording, we can also talk to the interpreters and explain to them that they are being recorded and processed in particle weight, and we also have the chance to a depth of them.
So we are trying to get their contacts.
We have still few months to come.
And even if they are non native, we should be able to a depth of their particular speech.
So we would cause them to do as the love.
Well, few minutes, the mob possibly up to an hour of of recording would pay them to what I read some.
Thanks to our our interpret something.
And then we were to create a training data set for that particular person.
And then obviously, we are going together in domain data at the southern and regularly.
Apollo eight.
So does the Sri.
We get the text sown know what, what do we know?
What do we expect?
Now, what that translation there, all the standard translation errors that you know where well.
So here is one example, a sentence, which was actually recognize perfectly.
I know which sentences are recognized perfectly.
So I know what to avoid when I 'm running demo of this is also different from the from the users of our system, they will simply is says," speak as they are used to.
If I want to showcase what our system is doing.
I will avoid named entities.
I will avoid strange constructions.
I will have like through and through newspaper, like a style of sentences, and then all the all the systems will successfully organized me.
So this is one of the the cases.
But it is much more difficult to to ask if you do not have any clue, and yet, the translations, both into German, and checked to sample languages were wrong.
The if was translated as all pow, 'rs dock, um.
And that is that black distorts the this towards the the sense of of that.
So might guess is that maybe in English, you would in in Native English.
You would actually say this a little bit differently.
And then there might be more explicit clue in the source.
And then I 'm not saying that the sentence in English is wrong.
I 'm saying that indeed training data, which is from news or maybe books, or or or you have legislation.
Men.
There is this slide domain.
Is much any even even if it is not domain mismatch.
This is is generally ambiguous conjunction, and it is difficult for the machine to guess the meaning.
So if you are closer to the training data, then you will see it will work better.
If if it is a difficult, an ambiguous expression.
You will have these problems moved to float like for ever yet.
Here is some some just misunderstanding or well, as the it was out of work.
Every the mission translation system, Ranald Hungary, you can be reported after some profanities.
So if you if you say something bad on your website, then they will flow like book, you know.
And that was the most translated as professional thinks that is because of the prophet is, we are not in the in the book of very of the mission translation system.
So the resorted to support expressions.
Okay, ah, the problem in spoken English translation is that the ants are Heiress.
Get kind of multiplied in machine translation.
If you have an error in speech recognition.
Then the error will be a few edits a single word similar in shape the what I have set.
But then you take this single word and you translated, and then the shape of the word" like the totally changes." So machine translation takes all the wrong words.
From the ears are as full of thrust forth and need happily real.
There is a sentence to make it the best possible sentence, including those strong words, and there is no information about the confidence, neither from this artist them, nor from the Mission foundation system.
So the so the user will be just left with the sentence, which sounds perfectly natural love mention some French entities, which were never never mention never part of the dog, because they come.
They come from an error.
So here is an example.
And the goal of my fees.
This is to fold, and there was two fold.
So instead of two fold.
This are good as this to fault, that is the natural like miss recognition of the empty output was.
And the goal of my theory is that of these is is to fall apart.
So there is definitely not what what we were after in this is that so that yet.
So this is.
This is what I would probably translate the downside it too.
If I was the one thing about.
I just wanted to highlight this to fold to miss recognize.
This twofold was translated as well as the bits that to fall apart.
And that is totally out of out of the scope.
Ok.
So what we have, what what is our plan for the mission translation, data, data data, and then maybe little bit of models.
So we are definitely going together more called a dump.
And in the universe that number is working on that.
We are going to get the more targets, side, monolingual data and make them slate that is for the domain adaptations.
So this is already think domain.
So we would like like you to focus on all these materials.
They are hardly Paolo.
Some of them are, but not too many, and especially not for those like 19, no new languages that we are also naming it.
So hopefully our baseline systems in the back translation will make some sensible output from that, and hopefully will be able to improve the vast inequality will create in domain test sets, and we regularly able wait on them.
We also tried to get in touch with the house.
Again.
That is the collection of the user supplied Apollo data, and they can give an artist says," they can extract the most similar sentences.
So to sum up like filtering off off larger pool of Apollo data.
We are also trying to create guess the tears solace tougher live on men into these like participants, or or the presidents of the Supreme audit office says," this is having just the list of names.
It is not ideal for formation translation.
What is that really better than nothing.
So we will.
We will try this as well.
I 'm also considering.
And this is something that maybe some one of you could try.
I 'm considering to to train machine translation on distorted source, because I would prefer.
The mission was, this is them to say something in the domain and sensible rather than to ah, to like to try to who and perfectly translate the wrong way us our output.
So for me, it tentatively.
I 'm saying that uh, it seems to be better to say something similar or related to read.
The Den is the like do perfect oscillation of the wrong import.
They will see whether this is good assumption, or not, if if the system starts making up the content.
Then obviously, the users will not be happy as well.
But right now, our system is too easy to to like that that that the that it is too easy to to note is that our system is doing something wrong, and we want to hide.
It is a bit under the carpet.
So let us see if this will be a good strategy or not.
And let us see if we manage to train such a motor, and I 'm afraid that we will never get she during this few months to the interesting things like this, this because gender.
Obviously.
The machine translation system has no information about the gender of the speech, the Pall.
They would have to his stood totally like Moon, Non labeled to have.
It does not know about that.
Thank you.
And no new English does not mark a most sentences for the gender of the speaker.
So it is very likely that our system will be just making up and switching the gender of the of the speaker in the first person sentences, and that will be very confusing for the audience.
So well, I 'm afraid that we will not get to this, unless there is someone who would like to okay.
Then the integration of the ace are an empty of order set s R.
M it is the rings off, lowercase words, mission transition expects individual couric sentences.
So there are number of options that we can try to bridge the gap.
So we can try to in their punctuation into the as our output, which we call the segmenter, or we can change the as sorrow to predicate directly couric, punctuation.
So the speech recognition with the run not into just sequence of forests, but sequence of words with punctuation and capitalization plan.
A student of mine is is working on this.
And we can also try something which is one of the research ghosts of our project that is for the end to end spoken language translation with one neural system that really gets the sound in one language and produces the translation in the in the target language right away.
So that is again part of Peter 's thesis.
So the segmenter given us three or four.
It is gets punctuation casing.
Could we use the other car stilts, ah, tool, some, so someone stool.
Unfortunately, the speech information is no longer accessible to this tool.
So it has just the sequence of words.
And based on the sequence of words.
It is guessing sentence boundaries.
And as one of my colleagues from the room.
A discourse specialists said," The is actually doing very good job given that it does not have any information about the pauses of all the information.
So it is surprising how well it can predict the sentence boundaries with this the poor information.
So still, it is it is far from perfect.
So there are many errors.
And there is also another to which the war to consider the intonation and and delays, but we have not had time to integrated.
So if someone would like to play around with that would be happy to it till we get to anyhow there.
So it was sunk.
It suggests rain this, this segment or tool on ching data, both four million sentences.
And here is the Precisians and recalls for various punctuation margins.
We are inserting and how highlighting the recall of period, because that is critical to to identify sentence boundaries.
So it is 70 to a to a two percent, which is reasonable, if you look at it as a number, but it is still far from sufficient for practical use.
Okay.
So here is an example of an error in in the us.
In the segmentation so Heiress, imprecision, only two confusing empty output.
So here, the speaker said," something like all too.
Well, that was part of a longer longer phrase, and the us are plus segmenter, but put a full stop between this lake in the middle of this phrase," relieving to the output.
This approach does not generalize all too and then separate sentence.
Well, so to somehow conclude that the whole talk.
So here the semantics is obviously changed quite bit.
This is exactly the case where the machine translation would burst one by one received the first sentence, and then the second sentence, and it would have no way to recover from a from the full stall, which should not be there in the first place.
So there to to sentence.
This would get like beautiful, but the the the message would be distorted errors in the recall, ah, make too much content, unstable, and will explain this on on on the following flights.
So here is another technical think uh, the the messaging between the speech recognition and spoke English translation.
So it is if it is the online speech recognition.
We are receiving text messages about this text messages.
Offspring was off.
Words are not related to sentence boundaries.
So in the first run.
And this is what we what we were mostly seeing in in March, or that is all the sessions that the word of tests for for the Supreme, what office.
We were receiving these messages.
So.
This is the first message, the second message, third message and 4th message, and we were directly sending these messages to the machine translation.
So the first message was you should think there have been, and they are.
They are still unfinished.
Invents machine translation system.
Given this implode decided to totally on with the first sentence, because the first, and then like does not feed.
Their mission transition system is trained to translate false and thence into full sentence.
So some half sentence here.
Let us drop it.
So it is said to just Dick.
We just think, you know, and then the law.
This is an extension of that message.
So the is our sent again, the same prefix.
And then it ended the extra words that came in the meantime.
And this is probably the best translation that the empty could have delivered for that, and then the his horse and something which we call the confirmation message.
So the is our says," well, I will not bother with these three words anymore.
You should think I will just love.
I 'm Phil finalizing these.
And from now on, I will only send you the rest.
There have been many revolutions.
So here is a single message.
You should think.
So that is one complete sentence.
And the beginning of another sentence, and we have translated as as if it was once.
And and that is that is just wrong, and then the next message stars in the middle of the sentence already.
And we are again feeding it as if it was a complete sense.
And so there is like the sentence boundaries are totally unobserved by our approach, and that that kills everything, and it emits it.
It is um greats all of these partial sentences into full sentences.
But that is not related to the the the what the what the people said," OK so.
If you put together the the as sorrow and the better.
And we did it in motion on the following size, then you still need to President somehow the result.
So that is where it is slowly coming towards the the final stage, and still, it can totally kill the the show.
Ah, this.
If you have found two small, such as in the subtitles, if they were a little bit smaller it.
They will not be of any use for you at all.
So you need to very carefully balance like how much content you put to somewhere.
And if the phone would be eligible.
If it is still, if it is legible for people in the first row.
And for the people in the last through if they have to rely on the cell phone.
And suddenly they have a different shape shape, different rectangular area where the translations and transcriptions.
Abby.
And this heavily affects how much information we can send for them, and we have to dynamically decide what what the sent them.
And and what not the, for example.
Then if if if this text, flickers too much.
If the worst change too quickly.
You can three them.
So that is one of the reasons why we have not employed the fully neural network as our system so far, because they are trained to operate on window that moves in time.
So uh, eight seconds at one go are always recognized, and the beginning can change.
So imagine eight seconds of my speech bank, and still like a Reed deciding what is the first word, as mostly the words do not change, but sometimes they do.
And if you have this long piece of text, and the like swaps that here.
And there ah, there and back on on various places.
In various worst.
You do not know how to follow that.
It is it is like on stable text.
So we are working on this on this integration.
And I wanted to highlight.
This presentation must be tested on stage.
You can have tested in simulation, like good that the sizing of that day, as the visibility from various areas that all can kill.
It can negatively affected in such way that it is not usable at all.
If you have ever order something from any shop, and it came, but it was like the wrong size.
I that to smaller too big.
Then, you know what I 'm talking about a in an issue up.
You have a picture of what you are buying.
But the picture is out of proportion.
If you do not know, if you are getting this big that it better, or or this tiny that bear the so it is it can be or have the wrong size, and that the same thing as here for or for the subtitles.
So here is one of the views that you have been.
Maybe you have been watching on your machines.
This is mainly for showcasing that we can around the translation into many target languages.
So we are showing two lines of subtitles in then languages, the moment, and this will be 40 43.
This is good to demonstrate that the system is following me, and it can create the fall slowly positive impression, because if you are following me any, if you understand my my my language.
Then you cannot do.
You can no longer read carefully.
What is in the in the sub titles, and you were only observed the right, keywords there.
So if I say something about subtitles, then you will see to to look in check than you will notice a low grade.
The system is recognizing this person, but you are not able to judge the quality of the sentences.
So the sentences, in fact, are pretty crappy, and they jump to quickly.
And if you if you did not understand me.
And you only had these two lines to follow.
Then you would get lost in the errors of as are empty.
So this is.
This is good to show off, but it is better for the use of.
So we have something else.
We also show much longer context.
So the is that X is a gross.
And here you have a no.
This was probably given in English.
And then it was translated into a check and German.
And he already see the difference between the stable output, the partial output and the like the incoming output.
So.
Some of these sentences are fully processed by all the pipeline of all the components in the pipeline.
And there is no way they could be updated any longer.
And these sentences are shown in are shown in black, and then their sentences, which are gradually being updated.
And here still the punctuation can can like make a difference.
So that is why we are showing this only in great.
And then there is the last sentence, which is still getting more and more words, and as the segmenter finishes processing of some of this.
And then the 4th some full stop.
Here will appear.
And it will be out of the uh, the processing area of of the segment there anymore, and it will become the black and full of stable output.
Here you see in the Y.
The full stop recall is important.
If the full stop are too scars there too in frequent in the output.
Then too much of text will remain in this gray face and do much of tics will like be still undecided in flickering, people will wait wait too long for the stable output.
And you also that it is also like matter of taste, whether people would like to follow the more the more unstable Maurice and output, or whether they would like to have full only the stable one, but be several seconds behind the speaker, so that the difference.
So this is something that we have to update.
And ideally, it would be the users choice.
Would you like to have the the the shortest possible delay at the risk office, the reading something which will be still like fixed, or would you like to wait little longer until our output is stable.
So that is something that the the ideally, the the user would choose who, so if people are provided with this longer context, then they can better recover from errors along the bike line.
So it is almost impossible to follow the content of a dog, which is not known to you.
If it is not too far from the domain of the training of the machine translation system.
Ah, again, and yet.
And so here is a little summary of what has to be done.
If you are presenting checks only in the two lines of supplied link.
So you have some this are.
So this is some English has three or four words, pixels on your screen.
At any given moment.
It is also very flexible.
Architecture of this is an entire book.
So you see that there is no assent and boundaries.
And the segmenter needs to predict some sentence boundaries soap.
It is predicted a full stop here and a full stop here.
And then some is our debate comes.
And it also based on this day, the segmenter has another update.
So it predicts one more full stop here.
So this is like a sequence is self updates coming.
And some of these sentences are already completed.
So the segmenter says," this full stop this final.
I will never never take it back do with this sentence, whatever you like, will not touch it to them.
Some of these.
Some of these force of are still unstable.
So I 'm a a remove this full stop, and I moved slightly.
And then we also have to to like handle that properly.
And then as the Us.
And the rest.
The last sentence is only Qs expected or incoming like we do not know what what the sentence.
What will finish like we are sending now full sentences to the machine translation system.
So that is the the there is like who good.
Now.
That means that the.
And this is them his brow of fed with the input is ready for.
So now, going into German.
It will say," let us that something like picks them all freedom.
Bill show him that suited him tight boom, could assist all.
I know is that flexible heretics, or as it is.
So.
So this makes this makes sense.
This is like Couric judgment, and then says," The issue is how much space you have to show this German to use it.
So if we have two lines of subtitles that, would that would show this yellow part and this yellow part.
And then, because the last sentence got some extra words.
It got extended, the the the system decided to change the beginning of of this sentence them.
They decided to change the last word on the first subtitle line.
If the lime this like still visible.
We can easily do the change.
And nothing bad happens.
If we are limited to just one line of subtitle output.
Then this line has been already rolled out like the the the the user can no longer seed the user, so it a second ago.
But now this is no longer accessible.
So we would have to show the like only half of the sentence, and that is something that we cannot do.
So the something has changed.
We call this.
The rest said," now, the now these sub.
Tightening mechanism has to go back and show something which has or disc rolled up and show it again.
So that is the user can read.
But this three said," is extremely annoying.
So you may have noticed noticed that sometimes this.
The subtitles got the right.
And the the wretch effect is exactly highlighting arrested has happened.
So the the the segmenter.
The second, most oscillating like where to put some of the full stops were to put the ah, the casing changes and gave the change of the full stop, or the casing happened above the edge in the line, which already rolled up.
Then the subtitle, even put here for a us are issued arrested, and it also indicated in red.
So the red for me.
It was like remote.
Yes.
This is the rest.
So this is the this is the case where the subtitles had to scroll back, because something was updated outside of the screen, so the dead.
But that is an illustration of why the limited out will space is so critical for delivering the that translation to the user, if you limit yourself, too much, if the language differences, too big.
And so the wards reordering and the length of the sentences of like make you read you larger bits that then fit on the final screen, then the user will be experiencing a very confusing resets.
So I 'm like stressing this, because this is something.
This is.
These are decisions that you make along the whole pipeline.
And it is only the very last bit the size of the window that kills it, or or makes it make it workable.
So that is that is why we are like fighting in the consortium.
Why?
What is the better output of the.
It seems based on these arguments that you would definitely do not want to have the subtitle soup.
You prefer you.
You should prefer the longer paragraph you that that you saw on the previous slide.
But the problem here is that if you if you make some very bad miss.
They gave some some bad word of some profanity appears in the output.
It will still be there for too long.
And people like that, they go their cell phones and and take pictures of the Bill that bed were.
So ah, you are exposing too much of of your problems in this that.
So that is why that is why the the some some partners in the consortium preferred the the subtitles.
But there is a big risk of of the subtitles being incomprehensible.
Ok.
So then there is the overall cognitive load, and the the the overall usability.
We have to users.
They are here who corn for him dead.
So so so no one over there.
There is many that that is another the the studies.
So there is so many users who have tried to follow.
This have said that that there is no way that you would be following the translation on your notebook.
And looking at the slides of the speaker, who is in front of you, even if it is like in the very close angle.
If you do not have to move your eyes too much.
You still have to accomodate because of the different distance, and, that will take some time.
And.
Then you will see as soon as you look up at the slides.
You will lose the subtitles, then you will lose content.
So we are now working on ending the slides, but also to the the screen where the subtitles appear, or the other way around putting subtitles to uh, to the screen, where that with the flies are.
So this is something which which has to be done.
And then the old usability.
The overall usability is still very bad love.
Inviting you whoever does not speak French, and would like to join us.
We are.
Hopefully this week, we are running like a French movie watching session, or just ten minutes of it that dark, we do not speak French.
So we will follow our systems, recognizing the French and translating into English, or or check or any other language.
Ain 't it.
We will try to come up with improvements that would make it actually usable because it is very big difference, whether you can understand the source language, or or not our.
We had a similar session with much improper presenting something on machine translation, evolution in check any Ross and then did by our to foreign students.
And these two foreign students reported that they could follow the checked dog, if they fully focused on the paragraph fuel, as soon as they looked upon the slides, they got lost.
So if with full attention to the slice.
It was possible to follow it.
But this is not for a normal users, like normally, use.
Those have to you have to have some free time for their for their brains as well.
I would like to highlight that that.
These are setting differs from Hughes Abuse it.
Those who understand the source language will need the similar to new Glee, and they would prefer it all or precision and stability, if you are following what I 'm saying," then the.
And if you are reading the subtitles in your mother tank, then they could provide you with the words that you missed.
If you do not understand word.
It could appear here.
You would understand it, but it has to be there, and the like on the spot.
And at the moment, when I said the word, if it is there are three seconds.
After then you, it was of no use to you any more, because it like you have moved in what you are listening already.
So if you are following the source language.
The subtitles in your Mother duncan help you, but they have to be immediate.
If you do not understand the source language, then you are only relying on the text.
And in that case, you would prefer stable it in precision, and you are happy to wait for second stewed.
You do not know what I 'm talking about it all.
So it is not a problem.
If if you get my message eight seconds later.
So this is two very different use cases.
And it should be the user to select, which which of the displays is the is that not not just OK so inhalation there.
Are three aspects of spoken English translation.
Quality does something that we know from machine translation.
And we know how to have vaguely estimate the translucent quality, but there is also the lake.
How much is the text in the translation delayed behind the source of some of the Lake is obviously inevitable, because you have to wait for the German verb, or we have to anticipate it in some way, and there is flicker.
So.
If you have a system, which is updating, and we have such systems.
Then these systems can anticipate, and they have the capacity to coring themselves.
So then suddenly they can create some output, and then remove it in the next step.
And this has to be controlled very much so that the user is not confuse.
So we are working on an evolution to with him an sorry, and hideous as as the them, the most serious problem.
If you have this English, as are the do.
You know, it is cat is not it.
Yes.
It is like that.
So let us imagine that the Segmenter has segmented into these two chunks.
There is no way to align it.
Well, with this German translation, their friends, because it has three sentences that the doors are grouped in a different way in the sentences.
So we have to do is somehow force align these.
So that the basic set of units that we are ever leading over is common to all systems, regardless of what the English.
As our does.
Uh, everybody has to reach the same references segmentation.
So there is some strategies.
I 'm not going into the into the bills, any more.
Essentially we have the option to work with these sentences, unlike consider more sentences at the same time, or we can totally forget sentences, and we can ever laid by employing 30 seconds chunks.
So did the the empty the as so the pipeline, the the uh.
So the pipeline produce the right words within these 30 seconds.
And if it did then, yes, if not the not.
So this is this is like way to go around the problems of sentence, this not being out there in in speech at all yet.
So the search for the mobilization.
As I as I say it.
The battle torso.
Usable system is still not lost.
So we are now building of an army of paid volunteers.
And if you have any pro colleagues or students who can help us between now and may or June, we are totally happy to take them on board.
So we are meeting at least once a week for just 30 minutes and discussing was working on lot, and we have funds for this.
So this is like ah, as a new paid work, and you can do many smallish tasks.
For example, if you are looking at some of the empty outputs.
There could have been bad characters, because no one has yet fly could check to where they come from in the pipeline.
Then there is larger, but the things that we need to develop.
We would like to have a as a dashboard, which we will give a configuration like a life system, running which gross locks thought look files and does that board should loss that immediately see, where is the problem.
So for example, if we are recognizing the English booth with the French, as are then there will be many of friendship words, coming from the systems, but they will be totally wrong.
There is the the most laughable output.
I have seen so far like swapping the languages for the as are because the the system still struggle.
It will be like says," The word" similar with pronunciation, but in the wrong language, and the sentences will not make any sense whatsoever.
So this can easily happen.
If you are following six imports and translating into 43 languages.
You need a concise view to to to know what your systems are doing.
So that would be dashboard.
Then a lot of work on that domain and speaker adaptation, just just getting in touch with all the interpret those who would be in the booth and conducting them, asking them to come here record an hour each.
And then using this, they have got to have the system.
Again.
A lot of a lot of little work coat, switching is something which I have not discussed in my talk at all.
But I 'm realizing how frequent it is not only in linguistic lectures, where we have examples in four languages, but also native speakers of other languages, the English frequently, but bring in English phrases, and the as our systems are totally not ready for that.
So then the it is very similar to to above the named expression or named.
And it is, it is simply an own words that get recognize into something very, very bad.
And then when this gets translated is still, there were laughable.
There is also another activity, which would really like to start call in leather climbing.
So it is when you have fixed tested, and your working on improvements have your model of or the pipeline.
So your making many small changes, and you are always overloading on that that is that is.
So you are climbing the leather of performance.
So this is this is what we have to run a.
I 'm hoping for like two bigger Modal rid.
The retraining says," until until may and many architecture changes, many like smaller fixes that can improve the disk or quite a bit paint.
You up for the talked about this.
So there is there is board, but it is still something different.
And they support is like technical.
Uh, set up.
You want to know that the sound volume from all the six imports.
This is the right was the small, the source monitor.
You assume that the technically the architecture is all set of well, but still, you need to decide which of the as are in the combination of the speaker works best, and which of these sources delivers the best translation quality into the many target languages.
So this is like a technical check that everything is running.
And this is selection of the best possible through the for the best.
The output wanted them to summarize of their leader subsiding, a is a big challenge for the project, even if you connect to superhuman components.
They can still Delhi were crept together.
So we are now working on making this usable, technically the complex pipeline now works.
It has been working.
How many restart as that you have to know do some good mother.
Okay?
So it is not seem less, but with one operator.
It can survive 60 minutes of of speech and the.
But unfortunately, even with this whole system, working the benefit for the end user is still limited or nonexistent.
So.
If you did not follow my English speech.
If you only had chance to read the check translation.
I 'm curious how much you would get.
So this is one of the.
We are true.
We have still a few months ago.
So I 'm very lucky that that.
We have these months to to fix the pipeline.
And some of the problems that will are running into are not going to be sold in the next two, three, five years.
But some of them can be fixed.
The soul will do our best to to make the the the output actually usable, and she goes to please.
Please join us.
Ah, because ah, is to be a blue with us that that is it.
So we have a technology, which technically works.
But it is totally unusable.
And and I 'm curious, how how far we get in in these months.
So we are running this.
This are male or this this mobilization.
So we seek for your help and just talk to any of us.
So maybe those view who are already on the search team will just raise your hand.
So that people see though one to three.
So the yacht so so at least for for people in the room already.
And if you have more of you.
If you have students who would like to get in touch with this.
This is a nice.
It is not summer.
Internship is like spring, spring internship.
Please, please, let them know, and you can read all the details about the project in the block.
And if you want the the real truth, then talk to us directly.
Yeah, OK thank.
You.
Thank.
You all.
At some details yet hunger.
Well, you spoke about the the the problem from a on this are.
If there is a mistake in understanding of the of the word.
And it brings the problem for her to go to the mission translation, and they also spoke about the the module, that puts the punctuation into into the steam of woe who works did.
Did you consider some some sink, like the moon, some sort of Brimmer trucker, or some language model.
Let us put it check whether the sample sentences are really sentences or dramatically good enough to be sent to machine translation was the most.
So yes, and no this whole punctuation insertion to segment.
There is the language model as such.
So that is that is like and Graham base, but it is not an graham.
It is it is longer sequences.
It is the neural network based and rang which more true.
And it is trained on the concatenated sentences.
But I think these sentences are concatenated from order shuffled training set.
So it has this like the sentences came became edges adjacent just by randomness, and not by a proper local context.
So there is a certain limitation.
So that is there is the best part of of that.
So it totally relies on some language model in the end, the statistical cents more and some grammatically," of the sentences in no, no, we are not considering that at all, because so well, we also do not assume that people would other Grammatically Court.
Sentences so that is the um the the, problem, or that does that you may be referring to the would be called speech reconstruction.
And this is something that that our Department has been working on in the boss as well they are.
The goal is to take the party disfluency speech of of myself and converted into a written like this beach, like proper all only all good choric for grammatically proper, sentences, but they were not working with with this component at all in in our system.
So quite on the contrary, we are there other moving towards a mission translation systems, which will be robust to translating even these a partial sentences.
So I have not mentioned in the slides, but another of students of mine dominick.
I 'm watching is working on on mission translation, which runs not on sentences, but on the window all for it is.
So we would like to get rid of the segmenter altogether, and new would.
Hopefully if if we provided with rose and good training data that has this property.
Then the transition system would be able to translate this through an sentences into disfluency vince 's usable in the target language, which care the question about the issue of where to place see our microphone, because several times.
I saw some speakers holding their microphone on that day chain, like a nice heavy overseas does frequent at all that the.
They claiming that it.
Is it is you?
Can?
It is gone from the understandable.
And and you prevent flowing here.
And there we have not tried.
So next next time.
You see me giving a talk about surely holding microphone, much cheaper to overloaded properly.
I realize that there is no laws because here in the room.
But when you put the microphone on the arch in your voice has changed here in like in the in the loud in the in the wild.
And so I do not know, maybe maybe the recording has not has not seen any change, but we have OK i.
Have two small questions of them.
One.
Question concerns or, it is a remark.
There is a thing that if intonation is separate you attention to, and then it might have for the signal.
And then she got, of course, in the throne speech.
People do not behave.
According to the rules that is that is I have one question for, you know, slide number for fortis, or we have to.
I just wonder that yet, though, though, between low in the 34.
In part.
You have kept it does not, but you do not have to change.
I think this is books.
Ok.
So, so we do not know, I do not know if we can actually give it a try and find a launch there is, but where where is this ant?
So.
And so here, ah, and die in.
So I will I will?
I will stop the live subtitles, because it is taking the or a pitch.
It had a visitor onset.
So I 'm I 'm curious myself because here is the present, because have one more general question, yes, so precise that if we just go to the paragraph you in the meantime gusts in the thin and the the moon.
So let us switch of the him D and Hungarian.
And and it is one and a zero.
So this is my English recognized, and it is being translated into German, and in to check a soaking up.
And and and a more general question, which may be.
You have heard seven times.
How much can you learn all?
Well, as studio, all considerations of if you all is going the of translators, interpreters interpreters it, just where the is simultaneous translation.
From the strategists also say that they are.
So is this something in the in the system, which would reflect this things mean, it is not yet.
Not at all.
We are in touch with them, because you like it.
It helps us.
So we, we think that then we can get hold of the data, but their interpretation strategies are much more along CA so.
The long-range.
So, to say, so, they are happy to listen to couple of sentences, even for the summit in his translations will soon within.
Those can still mean 20 seconds after that, and they will first give the whole idea, and they.
They will speak it from Scratch.
And this is very distant from what we are doing, but we are aiming to get into the same brain.
So to say, so we have no fool, our very first data sets where we have the source speech in English, which is being interpreted live into checked by some of these students.
And so we are also transcribing the English.
And we are translating in the text form.
What was said in English, and the evolution tool that I mentioned that will consider the quality in terms of full blessed or similar score for machine translation of the lake.
And the flicker is meant it is not just that, but it is meant to be applicable also to human interpreters.
So ideally, we would see that the human interpreters are much better in precision, or the the quality of the output, but they will be much slower.
They will have much longer lax, and they will always.
They have no flickers or burial likely they will.
Well, it will be difficult to transport, the flickers, because the the the way will be collecting the data so, but would really like to have automatic through that violates both facilities systems and interpreters in in the same three scales.
And then we see what all the complimentary benefits of of these were like groups of of processors.
They strategy.
So far are are not off any use it to us.
And also their evolution strategies are very distance from what we are like talking about.
So that that the that we have seen checklist of when they are being created the interpreters, and you have some.
Some of these items are are totally irrelevant to our technology.
Ok.
Thank you.
So I must change.
We have to stop at this point.
